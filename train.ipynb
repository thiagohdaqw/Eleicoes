{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d44d4c-aea3-45b2-80df-036345822d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer\n",
    "from pyspark.sql import SparkSession\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cc0bd3-6ef0-448c-b8ec-32d4637637e9",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf3b71c9-a0d3-4a3b-ac8b-27326a78b64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_FILE = \"dataset/dataset.csv\"\n",
    "MODEL_PATH = \"model/\"\n",
    "SPARK_MASTER = \"spark://localhost:5000\"\n",
    "SPARK_APP_NAME = \"Final - PSPD - Train\"\n",
    "KAFKA_SERVER = 'localhost:9093'\n",
    "PACKAGES = \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.2.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8451eed2-b8ea-4558-9216-abb7035d7559",
   "metadata": {},
   "source": [
    "## Startup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93a72a8-02d4-4265-8ed9-a54b096d558e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf() \\\n",
    "    .setMaster(SPARK_MASTER) \\\n",
    "    .setAppName(SPARK_APP_NAME) \\\n",
    "    .set(\"spark.jars.packages\", PACKAGES)\n",
    "    \n",
    "context = SparkContext(conf=conf)\n",
    "context.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc862f0-896c-4343-8209-8e42a9151170",
   "metadata": {},
   "source": [
    "## Ingest Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00f7fee-29b3-4963-ac3d-a331e6bcf4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = spark \\\n",
    "    .read \\\n",
    "    .format(\"csv\") \\\n",
    "    .option(\"sep\", \";\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .load(TRAINING_FILE) \\\n",
    "    .selectExpr(\"sentence\", \"CAST(sentiment AS FLOAT) AS label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239ace1d-bf9c-4294-9cd8-69217cd9faff",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0b6a89-c47a-4942-a5f6-3fdcd3b46721",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n",
    "hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\")\n",
    "lr = LogisticRegression()\n",
    "lrparamGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, [0.001, 0.01, 0.1, 0.5, 1.0, 2.0])\n",
    "             .addGrid(lr.elasticNetParam, [0.0, 0.25, 0.5, 0.75, 1.0])\n",
    "             .addGrid(lr.maxIter, [1, 5, 10, 20, 50])\n",
    "             .build())\n",
    "lrevaluator = RegressionEvaluator(metricName=\"rmse\")\n",
    "lrcv = CrossValidator(estimator = lr,\n",
    "                    estimatorParamMaps = lrparamGrid,\n",
    "                    evaluator = lrevaluator,\n",
    "                    numFolds = 5)\n",
    "pipeline = Pipeline(stages=[tokenizer, hashingTF, lrcv])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906bef28-05cf-4995-a1bf-00f8076a7cc9",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59277966-0680-496b-8900-732d96b859c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f75d67a-a3e7-4863-8cde-b98b1fc127cb",
   "metadata": {},
   "source": [
    "## Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e90390-66f7-4334-8112-b742e0dc5db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(F\"{MODEL_PATH}{datetime.now()}.model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
