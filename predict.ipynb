{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd5bd742-a154-4a55-a46f-a7ea3cafa129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.pipeline import PipelineModel\n",
    "from pyspark.sql.dataframe import DataFrame\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.functions import lower, when, col, udf, split, lit, format_string\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b891117c-0759-4a5d-94fc-189fe5bba57a",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b06223cf-9b18-4747-a4cb-0bac6216f341",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_FILE = os.getenv(\"TRAINING_FILE\",\"dataset/dataset.csv\")\n",
    "SPARK_MASTER = os.getenv(\"SPARK_MASTER\", \"spark://gpu3.esw:7077\")\n",
    "KAFKA_SERVER = os.getenv(\"KAFKA_SERVER\", 'localhost:9092')\n",
    "\n",
    "SPARK_APP_NAME = \"Final - PSPD - Predict\"\n",
    "INTERVAL = os.getenv(\"INTERVAL\", \"10 seconds\")\n",
    "\n",
    "PREDICT_TOPIC = os.getenv(\"PREDICT_TOPIC\", 'election')\n",
    "STATS_TOPIC = os.getenv(\"STATS_TOPIC\", 'test-elasticsearch-sink')\n",
    "\n",
    "PACKAGES = \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.2.0\"\n",
    "\n",
    "PRETRAINED_MODEL_PATH = os.getenv(\"PRETRAINED_MODEL_PATH\", \"model/trained.model\")\n",
    "STOPWORDS_PATH = os.getenv(\"STOPWORDS_PATH\", \"dataset/stopwords.txt\")\n",
    "\n",
    "SPARK_CORES_MAX = os.getenv(\"SPARK_CORES_MAX\", \"2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e16a5f-aacf-47e0-a96a-60bd32f65b01",
   "metadata": {},
   "source": [
    "## Startup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ecfb9ea-fbbf-41c3-876f-674535dfd199",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/rcleydsonr/spark-3.2.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.2.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/rcleydsonr/spark-3.2.2-bin-hadoop3.2/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/rcleydsonr/.ivy2/cache\n",
      "The jars for the packages stored in: /home/rcleydsonr/.ivy2/jars\n",
      "org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-605420fc-5cf7-4dad-a1f7-1cf27100cef8;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.spark#spark-sql-kafka-0-10_2.12;3.2.0 in central\n",
      "\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.2.0 in central\n",
      "\tfound org.apache.kafka#kafka-clients;2.8.0 in central\n",
      "\tfound org.lz4#lz4-java;1.7.1 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.8.4 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.30 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-runtime;3.3.1 in central\n",
      "\tfound org.spark-project.spark#unused;1.0.0 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-api;3.3.1 in central\n",
      "\tfound org.apache.htrace#htrace-core4;4.1.0-incubating in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.0 in central\n",
      "\tfound org.apache.commons#commons-pool2;2.6.2 in central\n",
      ":: resolution report :: resolve 1216ms :: artifacts dl 28ms\n",
      "\t:: modules in use:\n",
      "\tcom.google.code.findbugs#jsr305;3.0.0 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\torg.apache.commons#commons-pool2;2.6.2 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-api;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-runtime;3.3.1 from central in [default]\n",
      "\torg.apache.htrace#htrace-core4;4.1.0-incubating from central in [default]\n",
      "\torg.apache.kafka#kafka-clients;2.8.0 from central in [default]\n",
      "\torg.apache.spark#spark-sql-kafka-0-10_2.12;3.2.0 from central in [default]\n",
      "\torg.apache.spark#spark-token-provider-kafka-0-10_2.12;3.2.0 from central in [default]\n",
      "\torg.lz4#lz4-java;1.7.1 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.30 from central in [default]\n",
      "\torg.spark-project.spark#unused;1.0.0 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.8.4 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   13  |   0   |   0   |   0   ||   13  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-605420fc-5cf7-4dad-a1f7-1cf27100cef8\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 13 already retrieved (0kB/19ms)\n",
      "22/09/18 20:22:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/09/18 20:22:17 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "conf = SparkConf() \\\n",
    "    .setMaster(SPARK_MASTER) \\\n",
    "    .setAppName(SPARK_APP_NAME) \\\n",
    "    .set(\"spark.jars.packages\", PACKAGES) \\\n",
    "    .set(\"spark.cores.max\", \"2\")\n",
    "    \n",
    "context = SparkContext(conf=conf)\n",
    "context.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46c7cda4-1a80-4596-ae4a-eb2709436582",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbbfaf5-8bed-4e2b-8944-9a9552096258",
   "metadata": {},
   "source": [
    "## Cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5bd50a9-1d8f-466d-8d6f-f8a569b704be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "CLEAN_REGEX = r\"[.,/\\\\\\[\\]\\{\\}`~^\\d&!@#$%*\\)\\(\\'\\\"<>=+-:;?“]\"\n",
    "\n",
    "stopwords = set()\n",
    "\n",
    "with open(STOPWORDS_PATH, \"r\") as stop_file:\n",
    "    for w in stop_file:\n",
    "        stopwords.add(w.strip().lower())\n",
    "\n",
    "def cleaner(sentence):\n",
    "    sentence = \" \".join(\n",
    "        filter(\n",
    "            lambda x: x not in stopwords,\n",
    "            re.sub(CLEAN_REGEX, '', sentence).split()\n",
    "        )\n",
    "    )\n",
    "    return sentence\n",
    "\n",
    "cleaner_col = udf(lambda s: cleaner(s), StringType())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203786bf",
   "metadata": {},
   "source": [
    "## Load Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c56c630",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "model = PipelineModel.load(PRETRAINED_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0446fa-8a4d-419d-a6d6-5955ca1c13e3",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b31a2c1-70c5-42e8-889c-6dff59b78f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def foreach_batch_func(df: DataFrame, _):\n",
    "    # Preparations - split into candidate and message and clean\n",
    "    candidateMessage = split(df.value, \",\", 2)\n",
    "    sentences = df \\\n",
    "                .withColumn(\"candidate\", candidateMessage.getItem(0)) \\\n",
    "                .withColumn(\"sentence\", cleaner_col(lower(candidateMessage.getItem(1))))\n",
    "\n",
    "    # Predict\n",
    "    prediction = model.transform(sentences) \\\n",
    "                .select(\n",
    "                    \"candidate\",\n",
    "                    \"sentence\",\n",
    "                    \"probability\",\n",
    "                    when(col(\"prediction\") == 1.0, \"positive\").otherwise(\"negative\").alias(\"prediction\")\n",
    "                ) \\\n",
    "\n",
    "    # Write in console\n",
    "    prediction \\\n",
    "        .write \\\n",
    "        .format(\"console\") \\\n",
    "        .save()\n",
    "\n",
    "    # Prepare prediction to elasticsearch format\n",
    "    # Group by candidate and prediction and format to json\n",
    "    predictionElastic = prediction \\\n",
    "                        .groupBy(\n",
    "                            \"candidate\",\n",
    "                            \"prediction\"\n",
    "                        ).count() \\\n",
    "                        .select(\n",
    "                            lit('1').alias(\"key\"),\n",
    "                            format_string(\n",
    "                                \"{\\\"candidate\\\": \\\"%s\\\", \\\"%s\\\": %d}\",\n",
    "                                col(\"candidate\"), col(\"prediction\"), col(\"count\")\n",
    "                            ).alias(\"value\")\n",
    "                        )\n",
    "    \n",
    "    # Write to kafka elasticsearch topic\n",
    "    predictionElastic.write \\\n",
    "                    .format(\"kafka\") \\\n",
    "                    .option(\"kafka.bootstrap.servers\", KAFKA_SERVER) \\\n",
    "                    .option('topic', STATS_TOPIC) \\\n",
    "                    .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ee39d3-be33-4eec-b043-156b1c81a5be",
   "metadata": {},
   "source": [
    "## Sink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec95c249-6eeb-49a5-ae56-53c6910e20d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-----------+----------+\n",
      "|candidate|sentence|probability|prediction|\n",
      "+---------+--------+-----------+----------+\n",
      "+---------+--------+-----------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+--------------------+----------+\n",
      "|candidate|            sentence|         probability|prediction|\n",
      "+---------+--------------------+--------------------+----------+\n",
      "|     Lula|rt blogdomiro tuí...|[0.05473215335437...|  positive|\n",
      "|     Lula|rt carollinesarda...|[0.00176872172651...|  positive|\n",
      "|     Lula|rt houston_souza ...|[0.04372798265905...|  positive|\n",
      "|     Lula|felpweber pesquis...|[0.57049744512042...|  negative|\n",
      "|     Lula|dcm_online eleiçõ...|[0.01699080700473...|  positive|\n",
      "|     Lula|rt tradutordobr t...|[0.05473215335437...|  positive|\n",
      "|     Lula|rt fernandoholida...|[0.05473215335437...|  positive|\n",
      "|     Lula|rt skingotic reai...|[0.05473215335437...|  positive|\n",
      "|     Lula|rt tigrinhapnd gu...|[0.05473215335437...|  positive|\n",
      "|     Lula|obviamente cenári...|[0.08689507741586...|  positive|\n",
      "|Bolsonaro|rt radiogenova cr...|[0.05473215335437...|  positive|\n",
      "|Bolsonaro|rt jnascim sb “vi...|[0.89542213740066...|  negative|\n",
      "|Bolsonaro|rt mfriasoficial ...|[0.01699080700473...|  positive|\n",
      "|Bolsonaro|rt foiha_sp urgen...|[0.03992738801992...|  positive|\n",
      "|Bolsonaro|rt leonardodias v...|[5.14992064118603...|  positive|\n",
      "|Bolsonaro|rt athenasmgf des...|[0.03201002464161...|  positive|\n",
      "|Bolsonaro|rt houston_souza ...|[0.04372798265905...|  positive|\n",
      "|Bolsonaro|rt edschramer geo...|[0.03160743340872...|  positive|\n",
      "|Bolsonaro|rt anaclaramoniz ...|[0.05473215335437...|  positive|\n",
      "|Bolsonaro|rt soutimelula di...|[0.16245368674129...|  positive|\n",
      "+---------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+--------------------+----------+\n",
      "|candidate|            sentence|         probability|prediction|\n",
      "+---------+--------------------+--------------------+----------+\n",
      "|     Lula|rt kimpaim eleito...|[0.00513322302445...|  positive|\n",
      "|     Lula|rt terrabrasilnot...|[0.57200899456174...|  negative|\n",
      "|     Lula|    andrectelles mto|[0.05473215335437...|  positive|\n",
      "|     Lula|rt raimundodante ...|[0.13595631677014...|  positive|\n",
      "|     Lula|ouvindo anestesis...|[0.02005886618672...|  positive|\n",
      "|     Lula|rt oclannnn janei...|[0.03016229946684...|  positive|\n",
      "|     Lula|rt jrguzzofatos g...|[0.05473215335437...|  positive|\n",
      "|     Lula|racsouni clarisac...|[0.00919857986617...|  positive|\n",
      "|     Lula|rt eixopolitico ?...|[0.01699080700473...|  positive|\n",
      "|     Lula|rt jornalismojoao...|[0.01651828612116...|  positive|\n",
      "|Bolsonaro|rt pedrohu taliri...|[0.05473215335437...|  positive|\n",
      "|Bolsonaro|rt anneminas gent...|[0.02377783146400...|  positive|\n",
      "|Bolsonaro|rt alexandrekunz ...|[0.01784463538045...|  positive|\n",
      "|Bolsonaro|rt terrabrasilnot...|[0.05473215335437...|  positive|\n",
      "|Bolsonaro|rt ceclynch afirm...|[0.01699080700473...|  positive|\n",
      "|Bolsonaro|rt lira president...|[0.37423303445666...|  positive|\n",
      "|Bolsonaro|rt joserob visita...|[0.60939259033674...|  negative|\n",
      "|Bolsonaro|ouvindo anestesis...|[0.02005886618672...|  positive|\n",
      "|Bolsonaro|vídeo ótimo mostr...|[0.01471728835324...|  positive|\n",
      "|Bolsonaro|rt hermanntertsch...|[0.00276376423041...|  positive|\n",
      "+---------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+--------------------+----------+\n",
      "|candidate|            sentence|         probability|prediction|\n",
      "+---------+--------------------+--------------------+----------+\n",
      "|     Lula|         nhann livre|[0.02433642334546...|  positive|\n",
      "|     Lula|rt vaibrasil vamo...|[0.50792903147364...|  negative|\n",
      "|     Lula|rt linsaquiles je...|[0.05473215335437...|  positive|\n",
      "|     Lula|demori enterrar e...|[0.00642662134076...|  positive|\n",
      "|     Lula|rt pedroronchi vo...|[0.02156316250035...|  positive|\n",
      "|     Lula|inaciocaotico lul...|[0.42967398700241...|  positive|\n",
      "|     Lula|rt ____leh jairme...|[0.05473215335437...|  positive|\n",
      "|     Lula|rt carvalho_a_hel...|[0.52954216306748...|  negative|\n",
      "|     Lula|presidente turno ...|[0.20457842099022...|  positive|\n",
      "|     Lula|rt jrguzzofatos g...|[0.05473215335437...|  positive|\n",
      "|Bolsonaro|rt brom_elisa ima...|[0.01836784594453...|  positive|\n",
      "|Bolsonaro|rt filipesabara r...|[0.04707871155792...|  positive|\n",
      "|Bolsonaro|rt andreporci tro...|[0.05473215335437...|  positive|\n",
      "|Bolsonaro|rt marcelosantosm...|[0.05473215335437...|  positive|\n",
      "|Bolsonaro|rt jackposobiec w...|[0.01699080700473...|  positive|\n",
      "|Bolsonaro|rt amelialimab fi...|[0.05473215335437...|  positive|\n",
      "|Bolsonaro|rt manuels londre...|[0.05473215335437...|  positive|\n",
      "|Bolsonaro|folha voz bolsona...|[0.05473215335437...|  positive|\n",
      "|Bolsonaro|rt joserob visita...|[0.60939259033674...|  negative|\n",
      "|Bolsonaro|rt rconstantino b...|[0.01699080700473...|  positive|\n",
      "+---------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "lines = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", KAFKA_SERVER) \\\n",
    "    .option(\"subscribe\", PREDICT_TOPIC) \\\n",
    "    .option(\"failOnDataLoss\", \"false\") \\\n",
    "    .load() \\\n",
    "    .writeStream \\\n",
    "    .foreachBatch(foreach_batch_func) \\\n",
    "    .option(\"checkpointLocation\", \"/tmp/spark/mllib-predict\") \\\n",
    "    .trigger(processingTime=INTERVAL) \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b62552-5398-48a7-ae97-852f095f7b87",
   "metadata": {},
   "source": [
    "# End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc721391-1f82-4344-bd48-e672569b95fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a84f92-467a-4e3a-bf9f-f734226abc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()\n",
    "context.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('3.7.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "ed51b0d4d802ee6bae50f5ea08abdf9a7a07ae976ce5019e7e29aaee23a066c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
